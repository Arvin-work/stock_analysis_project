# ==============================================================================
# å¯¼å…¥ä¾èµ–åº“
# ==============================================================================
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
import os
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“ï¼ˆå¯é€‰ï¼‰
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

# ==============================================================================
# è®¾å¤‡é…ç½® - é’ˆå¯¹MacBook Pro Mç³»åˆ—èŠ¯ç‰‡ä¼˜åŒ–
# ==============================================================================
def setup_device():
    """è®¾ç½®è®¡ç®—è®¾å¤‡ï¼Œä¼˜å…ˆä½¿ç”¨MPSï¼ˆMac GPUï¼‰"""
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print(f"ğŸš€ ä½¿ç”¨MacBook Pro GPU (MPS)è¿›è¡ŒåŠ é€Ÿ")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("ğŸš€ ä½¿ç”¨NVIDIA GPUè¿›è¡ŒåŠ é€Ÿ")
    else:
        device = torch.device("cpu")
        print("âš ï¸ ä½¿ç”¨CPUè¿›è¡Œè®¡ç®— - å»ºè®®åœ¨MacBook Proä¸Šä½¿ç”¨MPS")
    
    return device

# ==============================================================================
# æ•°æ®åŠ è½½å’Œé¢„å¤„ç†æ¨¡å—
# ==============================================================================
class StockDataProcessor:
    """è‚¡ç¥¨æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, sequence_length=10, test_size=0.2, validation_size=0.1):
        self.sequence_length = sequence_length
        self.test_size = test_size
        self.validation_size = validation_size
        self.scaler = MinMaxScaler()
        self.feature_names = []
        self.df_processed = None  # ä¿å­˜å¤„ç†åçš„æ•°æ®æ¡†
        
    def load_data(self, data_path):
        """åŠ è½½CSVæ•°æ®æ–‡ä»¶"""
        print(f"ğŸ“ æ­£åœ¨åŠ è½½æ•°æ®: {data_path}")
        
        try:
            # å°è¯•ä¸åŒçš„ç¼–ç æ–¹å¼
            try:
                df = pd.read_csv(data_path, encoding='utf-8')
            except:
                df = pd.read_csv(data_path, encoding='gbk')
            
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape[0]}è¡Œ, {df.shape[1]}åˆ—")
            print(f"æ•°æ®åˆ—å: {df.columns.tolist()}")
            return df
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def preprocess_features(self, df):
        """ç‰¹å¾å·¥ç¨‹å’Œæ•°æ®é¢„å¤„ç†"""
        print("ğŸ”§ æ­£åœ¨è¿›è¡Œç‰¹å¾å·¥ç¨‹...")
        
        # åŸºç¡€ç‰¹å¾ - ç¡®ä¿åˆ—ååŒ¹é…
        base_features = ['å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡']
        
        # æ£€æŸ¥å®é™…å¯ç”¨çš„åˆ—
        available_features = []
        for feature in base_features:
            if feature in df.columns:
                available_features.append(feature)
            else:
                print(f"âš ï¸ ç‰¹å¾ '{feature}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        df_processed = df.copy()
        
        # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        if 'æ”¶ç›˜' in df.columns:
            # ç§»åŠ¨å¹³å‡çº¿
            df_processed['MA5'] = df['æ”¶ç›˜'].rolling(window=5).mean()
            df_processed['MA10'] = df['æ”¶ç›˜'].rolling(window=10).mean()
            df_processed['MA20'] = df['æ”¶ç›˜'].rolling(window=20).mean()
            
            # ä»·æ ¼åŠ¨é‡
            df_processed['Momentum'] = df['æ”¶ç›˜'] - df['æ”¶ç›˜'].shift(5)
            
            # æ³¢åŠ¨ç‡
            df_processed['Volatility'] = df['æ”¶ç›˜'].rolling(window=5).std()
            
            available_features.extend(['MA5', 'MA10', 'MA20', 'Momentum', 'Volatility'])
        
        # å¤„ç†NaNå€¼
        df_processed = df_processed.fillna(method='bfill').fillna(method='ffill')
        
        self.feature_names = available_features
        print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œä½¿ç”¨{len(available_features)}ä¸ªç‰¹å¾: {available_features}")
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®æ¡†
        self.df_processed = df_processed
        
        return df_processed[available_features].values, available_features
    
    def create_sequences(self, data):
        """åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®"""
        X, y = [], []
        
        for i in range(len(data) - self.sequence_length):
            X.append(data[i:(i + self.sequence_length)])
            # é¢„æµ‹ä¸‹ä¸€æ—¥çš„æ”¶ç›˜ä»·ï¼ˆå‡è®¾æ”¶ç›˜ä»·åœ¨ç‰¹å¾ä¸­çš„ç´¢å¼•ä¸º1ï¼‰
            y.append(data[i + self.sequence_length, 1])
        
        return np.array(X), np.array(y)
    
    def prepare_datasets(self, data_path):
        """å‡†å¤‡è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†"""
        # åŠ è½½æ•°æ®
        df = self.load_data(data_path)
        
        # ç‰¹å¾å·¥ç¨‹
        data, feature_names = self.preprocess_features(df)
        
        # æ•°æ®æ ‡å‡†åŒ–
        data_scaled = self.scaler.fit_transform(data)
        print("âœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆ")
        
        # åˆ›å»ºåºåˆ—
        X, y = self.create_sequences(data_scaled)
        print(f"âœ… åºåˆ—åˆ›å»ºå®Œæˆ: {X.shape} -> {y.shape}")
        
        # æ•°æ®é›†åˆ’åˆ†
        total_size = len(X)
        test_size = int(total_size * self.test_size)
        validation_size = int(total_size * self.validation_size)
        train_size = total_size - test_size - validation_size
        
        X_train, y_train = X[:train_size], y[:train_size]
        X_val, y_val = X[train_size:train_size+validation_size], y[train_size:train_size+validation_size]
        X_test, y_test = X[train_size+validation_size:], y[train_size+validation_size:]
        
        print(f"ğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
        print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
        print(f"   éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬") 
        print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
        
        return X_train, X_val, X_test, y_train, y_val, y_test, df, feature_names
    
    def get_processed_data(self):
        """è·å–å¤„ç†åçš„æ•°æ®"""
        if self.df_processed is not None:
            return self.df_processed[self.feature_names].values
        else:
            raise ValueError("æ•°æ®å°šæœªå¤„ç†ï¼Œè¯·å…ˆè°ƒç”¨prepare_datasetsæ–¹æ³•")
        

# ==============================================================================
# æ•°æ®é›†ç±»å®šä¹‰
# ==============================================================================
class StockDataset(Dataset):
    """PyTorchè‚¡ç¥¨æ•°æ®é›†"""
    
    def __init__(self, features, targets, device):
        self.features = torch.FloatTensor(features)
        self.targets = torch.FloatTensor(targets)
        self.device = device
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        return self.features[idx].to(self.device), self.targets[idx].to(self.device)

# ==============================================================================
# ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰ - ä¿®å¤æƒé‡åˆå§‹åŒ–é—®é¢˜
# ==============================================================================
class AdvancedStockPredictor(nn.Module):
    """é«˜çº§è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ - é’ˆå¯¹æ—¶é—´åºåˆ—ä¼˜åŒ–"""
    
    def __init__(self, input_size, hidden_size=128, num_layers=3, output_size=1, dropout=0.3):
        super(AdvancedStockPredictor, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # ==============================================================================
        # ç¼–ç å™¨éƒ¨åˆ† - LSTMå±‚
        # ==============================================================================
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout,
            bidirectional=False  # å•å‘LSTMï¼Œå‡å°‘è®¡ç®—é‡
        )
        
        # ==============================================================================
        # æ³¨æ„åŠ›æœºåˆ¶
        # ==============================================================================
        self.attention = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.Tanh(),
            nn.Linear(hidden_size // 2, 1),
            nn.Softmax(dim=1)
        )
        
        # ==============================================================================
        # è§£ç å™¨éƒ¨åˆ† - å…¨è¿æ¥å±‚
        # ==============================================================================
        self.fc_layers = nn.Sequential(
            nn.Linear(hidden_size, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(dropout),
            
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.BatchNorm1d(32),
            nn.Dropout(dropout),
            
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, output_size)
        )
        
        # ==============================================================================
        # åˆå§‹åŒ–æƒé‡ - ä¿®å¤ç‰ˆæœ¬
        # ==============================================================================
        self._initialize_weights()
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡ - ä¿®å¤ä¸€ç»´å¼ é‡é—®é¢˜"""
        for name, param in self.named_parameters():
            if 'weight' in name:
                if param.dim() >= 2:  # åªå¯¹äºŒç»´åŠä»¥ä¸Šçš„æƒé‡ä½¿ç”¨Xavieråˆå§‹åŒ–
                    if 'lstm' in name:
                        nn.init.orthogonal_(param)
                    else:
                        nn.init.xavier_uniform_(param)
                else:
                    # å¯¹ä¸€ç»´æƒé‡ä½¿ç”¨æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–
                    nn.init.normal_(param, mean=0.0, std=0.01)
            elif 'bias' in name:
                nn.init.constant_(param, 0.0)
    
    def forward(self, x):
        batch_size = x.size(0)
        
        # LSTMå‰å‘ä¼ æ’­
        lstm_out, (hidden, cell) = self.lstm(x)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        attention_weights = self.attention(lstm_out)
        context_vector = torch.sum(attention_weights * lstm_out, dim=1)
        
        # å…¨è¿æ¥å±‚
        output = self.fc_layers(context_vector)
        
        return output

# ==============================================================================
# ç®€åŒ–ç‰ˆæ¨¡å‹ - å¦‚æœé«˜çº§æ¨¡å‹ä»æœ‰é—®é¢˜
# ==============================================================================
class SimpleStockPredictor(nn.Module):
    """ç®€åŒ–ç‰ˆè‚¡ç¥¨é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=1, dropout=0.2):
        super(SimpleStockPredictor, self).__init__()
        
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout
        )
        
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, 32),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(32, output_size)
        )
    
    def forward(self, x):
        lstm_out, (hidden, cell) = self.lstm(x)
        last_output = lstm_out[:, -1, :]  # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        output = self.fc(last_output)
        return output

# ==============================================================================

def setup_device():
    """è®¾ç½®è®¡ç®—è®¾å¤‡ï¼Œä¼˜å…ˆä½¿ç”¨MPSï¼ˆMac GPUï¼‰"""
    print("ğŸ” æ­£åœ¨æ£€æµ‹å¯ç”¨è®¾å¤‡...")
    
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print(f"âœ… ä½¿ç”¨MacBook Pro GPU (MPS)è¿›è¡ŒåŠ é€Ÿ")
        
        # è·å–MPSè®¾å¤‡ä¿¡æ¯
        if hasattr(torch.backends, 'mps') and hasattr(torch.backends.mps, 'is_available'):
            print(f"   MPSåç«¯å¯ç”¨: {torch.backends.mps.is_available()}")
            print(f"   MPSå·²æ„å»º: {torch.backends.mps.is_built()}")
            
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        gpu_name = torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else "Unknown"
        print(f"âœ… ä½¿ç”¨NVIDIA GPUè¿›è¡ŒåŠ é€Ÿ: {gpu_name}")
        print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
        
        # æ˜¾ç¤ºGPUå†…å­˜ä¿¡æ¯
        if torch.cuda.device_count() > 0:
            memory_allocated = torch.cuda.memory_allocated(0) / 1024**3  # GB
            memory_cached = torch.cuda.memory_reserved(0) / 1024**3  # GB
            print(f"   GPUå†…å­˜ä½¿ç”¨: {memory_allocated:.2f}GB / {memory_cached:.2f}GB")
    else:
        device = torch.device("cpu")
        print("âš ï¸  ä½¿ç”¨CPUè¿›è¡Œè®¡ç®— - å»ºè®®åœ¨MacBook Proä¸Šä½¿ç”¨MPS")
        print(f"   CPUæ ¸å¿ƒæ•°: {os.cpu_count()}")
    
    print(f"ğŸ¯ æœ€ç»ˆé€‰æ‹©çš„è®¾å¤‡: {device}")
    return device

def print_device_status(device, step_name=""):
    """æ‰“å°å½“å‰è®¾å¤‡çŠ¶æ€"""
    print(f"\nğŸ“Š è®¾å¤‡çŠ¶æ€æ£€æŸ¥ [{step_name}]:")
    print(f"   å½“å‰è®¾å¤‡: {device}")
    
    if device.type == 'mps':
        # MPSè®¾å¤‡çŠ¶æ€
        print(f"   MPSè®¾å¤‡çŠ¶æ€: æ´»è·ƒ")
        
    elif device.type == 'cuda':
        # CUDAè®¾å¤‡çŠ¶æ€
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated(device) / 1024**3
            memory_cached = torch.cuda.memory_reserved(device) / 1024**3
            utilization = torch.cuda.utilization(device) if hasattr(torch.cuda, 'utilization') else "N/A"
            
            print(f"   GPUå†…å­˜: {memory_allocated:.2f}GB / {memory_cached:.2f}GB")
            print(f"   GPUåˆ©ç”¨ç‡: {utilization}%")
        else:
            print("   CUDAä¸å¯ç”¨")
    
    elif device.type == 'cpu':
        # CPUçŠ¶æ€
        import psutil
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        print(f"   CPUä½¿ç”¨ç‡: {cpu_percent}%")
        print(f"   å†…å­˜ä½¿ç”¨: {memory.used/1024**3:.1f}GB / {memory.total/1024**3:.1f}GB")
    
    print("-" * 50)


# æ¨¡å‹è®­ç»ƒå™¨ç±»
# ==============================================================================
class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, model, device, model_save_path='best_model.pth'):
        self.model = model
        self.device = device
        self.model_save_path = model_save_path
        self.train_losses = []
        self.val_losses = []
        self.learning_rates = []

    def print_training_device_info(self, train_loader, val_loader):
        """æ‰“å°è®­ç»ƒè®¾å¤‡ä¿¡æ¯"""
        print("\nğŸ¯ è®­ç»ƒè®¾å¤‡è¯¦ç»†ä¿¡æ¯:")
        print(f"   æ¨¡å‹è®¾å¤‡: {next(self.model.parameters()).device}")
        print(f"   è®­ç»ƒæ•°æ®æ‰¹æ¬¡: {len(train_loader)}")
        print(f"   éªŒè¯æ•°æ®æ‰¹æ¬¡: {len(val_loader)}")
        
        # æ£€æŸ¥ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®è®¾å¤‡
        sample_batch, sample_target = next(iter(train_loader))
        print(f"   æ•°æ®æ‰¹æ¬¡è®¾å¤‡: {sample_batch.device}")
        print(f"   ç›®æ ‡å€¼è®¾å¤‡: {sample_target.device}")
        print(f"   æ‰¹æ¬¡å½¢çŠ¶: {sample_batch.shape}")
        print(f"   ç›®æ ‡å½¢çŠ¶: {sample_target.shape}")
        
    def train_epoch(self, train_loader, criterion, optimizer):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        epoch_loss = 0
        
        for batch_X, batch_y in train_loader:
            batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
            
            optimizer.zero_grad()
            outputs = self.model(batch_X)
            loss = criterion(outputs.squeeze(), batch_y)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            epoch_loss += loss.item()
        
        return epoch_loss / len(train_loader)
    
    def validate_epoch(self, val_loader, criterion):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        epoch_loss = 0
        
        with torch.no_grad():
            for batch_X, batch_y in val_loader:
                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                outputs = self.model(batch_X)
                loss = criterion(outputs.squeeze(), batch_y)
                epoch_loss += loss.item()
        
        return epoch_loss / len(val_loader)
    
    def train_model(self, train_loader, val_loader, epochs=200, learning_rate=0.001, patience=20):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        
        criterion = nn.HuberLoss()  # å¯¹å¼‚å¸¸å€¼æ›´é²æ£’çš„æŸå¤±å‡½æ•°
        optimizer = optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, 
                                                       patience=10)
        
        best_val_loss = float('inf')
        patience_counter = 0
        
        # è®­ç»ƒå¼€å§‹æ—¶é—´
        import time
        start_time = time.time()
        
        for epoch in range(epochs):
            # è®­ç»ƒå’ŒéªŒè¯ - ä¿®å¤ï¼šç§»é™¤å¤šä½™çš„epochå‚æ•°
            train_loss = self.train_epoch(train_loader, criterion, optimizer)
            val_loss = self.validate_epoch(val_loader, criterion)
            
            # è®°å½•å†å²
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.learning_rates.append(optimizer.param_groups[0]['lr'])
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(val_loss)
            
            # æ—©åœæ£€æŸ¥
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'train_loss': train_loss,
                    'val_loss': val_loss,
                }, self.model_save_path)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯æŸå¤±: {val_loss:.6f}")
            else:
                patience_counter += 1
            
            # æ‰“å°è®­ç»ƒä¿¡æ¯
            if (epoch + 1) % 10 == 0:
                lr = optimizer.param_groups[0]['lr']
                elapsed_time = time.time() - start_time
                eta = (elapsed_time / (epoch + 1)) * (epochs - epoch - 1)
                
                print(f'Epoch [{epoch+1:3d}/{epochs}] | '
                      f'Train Loss: {train_loss:.6f} | '
                      f'Val Loss: {val_loss:.6f} | '
                      f'LR: {lr:.2e} | '
                      f'æ—¶é—´: {elapsed_time/60:.1f}m | '
                      f'ETA: {eta/60:.1f}m | '
                      f'Patience: {patience_counter}/{patience}')
            
            # æ—©åœ
            if patience_counter >= patience:
                print(f"ğŸ›‘ æ—©åœè§¦å‘äºç¬¬ {epoch+1} è½®")
                break
        
        total_time = time.time() - start_time
        print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ€»æ—¶é—´: {total_time/60:.1f}åˆ†é’Ÿ")
        print(f"   æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
        print(f"   æ€»è®­ç»ƒè½®æ•°: {epoch+1}")
        
        # æœ€ç»ˆè®¾å¤‡çŠ¶æ€
        print_device_status(self.device, "è®­ç»ƒå®Œæˆå")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        try:
            checkpoint = torch.load(self.model_save_path)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… åŠ è½½æœ€ä½³æ¨¡å‹ (Epoch {checkpoint['epoch']})")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æœ€ä½³æ¨¡å‹å¤±è´¥: {e}ï¼Œä½¿ç”¨å½“å‰æ¨¡å‹")
        
        return self.train_losses, self.val_losses

# ==============================================================================
# æ¨¡å‹è¯„ä¼°å™¨ç±»
# ==============================================================================
class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(self, model, scaler, device):
        self.model = model
        self.scaler = scaler
        self.device = device
    
    def evaluate_model(self, test_loader):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        self.model.eval()
        
        predictions = []
        actuals = []
        
        with torch.no_grad():
            for batch_X, batch_y in test_loader:
                batch_X = batch_X.to(self.device)
                outputs = self.model(batch_X)
                predictions.extend(outputs.cpu().numpy())
                actuals.extend(batch_y.cpu().numpy())
        
        predictions = np.array(predictions).flatten()
        actuals = np.array(actuals).flatten()
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        mse = mean_squared_error(actuals, predictions)
        mae = mean_absolute_error(actuals, predictions)
        rmse = np.sqrt(mse)
        
        # è®¡ç®—RÂ²åˆ†æ•°
        ss_res = np.sum((actuals - predictions) ** 2)
        ss_tot = np.sum((actuals - np.mean(actuals)) ** 2)
        r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
        
        metrics = {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'R2': r2
        }
        
        print("\n" + "="*50)
        print("ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ")
        print("="*50)
        print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.6f}")
        print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.6f}")
        print(f"å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.6f}")
        print(f"å†³å®šç³»æ•° (RÂ²): {r2:.4f}")
        print("="*50)
        
        return predictions, actuals, metrics
    
    def inverse_transform_predictions(self, predictions, actuals, feature_index=1):
        """å°†æ ‡å‡†åŒ–åçš„é¢„æµ‹å€¼åæ ‡å‡†åŒ–"""
        # åˆ›å»ºè™šæ‹Ÿæ•°ç»„ç”¨äºåæ ‡å‡†åŒ–
        dummy_pred = np.zeros((len(predictions), len(self.scaler.scale_)))
        dummy_actual = np.zeros((len(actuals), len(self.scaler.scale_)))
        
        dummy_pred[:, feature_index] = predictions
        dummy_actual[:, feature_index] = actuals
        
        predictions_inverse = self.scaler.inverse_transform(dummy_pred)[:, feature_index]
        actuals_inverse = self.scaler.inverse_transform(dummy_actual)[:, feature_index]
        
        return predictions_inverse, actuals_inverse

# ==============================================================================
# å¯è§†åŒ–å·¥å…·ç±»
# ==============================================================================
class VisualizationTools:
    """å¯è§†åŒ–å·¥å…·ç±»"""
    
    @staticmethod
    def plot_training_history(train_losses, val_losses, learning_rates):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # æŸå¤±æ›²çº¿
        ax1.plot(train_losses, label='è®­ç»ƒæŸå¤±', alpha=0.7)
        ax1.plot(val_losses, label='éªŒè¯æŸå¤±', alpha=0.7)
        ax1.set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å­¦ä¹ ç‡æ›²çº¿
        ax2.plot(learning_rates, color='red', alpha=0.7)
        ax2.set_title('å­¦ä¹ ç‡å˜åŒ–')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Learning Rate')
        ax2.set_yscale('log')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    @staticmethod
    def plot_predictions(predictions, actuals, dates, title="é¢„æµ‹ç»“æœå¯¹æ¯”"):
        """ç»˜åˆ¶é¢„æµ‹ç»“æœå¯¹æ¯”å›¾"""
        plt.figure(figsize=(15, 8))
        
        plt.plot(dates, actuals, label='å®é™…ä»·æ ¼', color='blue', linewidth=2, alpha=0.8)
        plt.plot(dates, predictions, label='é¢„æµ‹ä»·æ ¼', color='red', linestyle='--', linewidth=2, alpha=0.8)
        
        plt.title(title, fontsize=14)
        plt.xlabel('æ—¥æœŸ')
        plt.ylabel('ä»·æ ¼')
        plt.legend()
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
        
        # æ‰“å°å‰10ä¸ªé¢„æµ‹ç»“æœ
        print("\nå‰10ä¸ªé¢„æµ‹ç»“æœå¯¹æ¯”:")
        print("æ—¥æœŸ\t\tå®é™…ä»·æ ¼\té¢„æµ‹ä»·æ ¼\tè¯¯å·®")
        print("-" * 50)
        for i in range(min(10, len(predictions))):
            error = abs(actuals[i] - predictions[i])
            print(f"{dates[i]}\t{actuals[i]:.2f}\t\t{predictions[i]:.2f}\t\t{error:.2f}")

# ==============================================================================
# ä¸»æ‰§è¡Œç±» - ä¿®å¤ç‰ˆæœ¬
# ==============================================================================
class StockPricePredictor:
    """è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ä¸»ç±»"""
    
    def __init__(self, sequence_length=15, test_size=0.15, validation_size=0.15, use_simple_model=False):
        # è®¾ç½®è®¾å¤‡
        self.device = setup_device()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.data_processor = StockDataProcessor(sequence_length, test_size, validation_size)
        self.model = None
        self.trainer = None
        self.evaluator = None
        self.visualizer = VisualizationTools()
        self.use_simple_model = use_simple_model
        
    def run_pipeline(self, data_path, epochs=100, batch_size=32, learning_rate=0.001):
        """è¿è¡Œå®Œæ•´é¢„æµ‹æµç¨‹"""
        print("ğŸ¯ å¼€å§‹è‚¡ç¥¨ä»·æ ¼é¢„æµ‹æµç¨‹")
        print("="*60)
        
        try:
            # ==============================================================================
            # æ•°æ®å‡†å¤‡é˜¶æ®µ
            # ==============================================================================
            print("\nğŸ“Š é˜¶æ®µ1: æ•°æ®å‡†å¤‡")
            X_train, X_val, X_test, y_train, y_val, y_test, df, feature_names = \
                self.data_processor.prepare_datasets(data_path)
            
            # ==============================================================================
            # æ¨¡å‹æ„å»ºé˜¶æ®µ
            # ==============================================================================
            print("\nğŸ§  é˜¶æ®µ2: æ¨¡å‹æ„å»º")
            input_size = len(feature_names)
            
            if self.use_simple_model:
                print("ä½¿ç”¨ç®€åŒ–ç‰ˆæ¨¡å‹...")
                self.model = SimpleStockPredictor(
                    input_size=input_size,
                    hidden_size=64,
                    num_layers=2,
                    dropout=0.2
                ).to(self.device)
            else:
                print("ä½¿ç”¨é«˜çº§æ¨¡å‹...")
                self.model = AdvancedStockPredictor(
                    input_size=input_size,
                    hidden_size=128,
                    num_layers=3,
                    dropout=0.3
                ).to(self.device)
            
            print(f"âœ… æ¨¡å‹æ„å»ºå®Œæˆ: {sum(p.numel() for p in self.model.parameters()):,} å‚æ•°")
            
            # ==============================================================================
            # æ•°æ®åŠ è½½å™¨å‡†å¤‡
            # ==============================================================================
            train_dataset = StockDataset(X_train, y_train, self.device)
            val_dataset = StockDataset(X_val, y_val, self.device)
            test_dataset = StockDataset(X_test, y_test, self.device)
            
            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
            
            # ==============================================================================
            # æ¨¡å‹è®­ç»ƒé˜¶æ®µ
            # ==============================================================================
            print("\nğŸš€ é˜¶æ®µ3: æ¨¡å‹è®­ç»ƒ")
            self.trainer = ModelTrainer(self.model, self.device, 'best_stock_model.pth')
            train_losses, val_losses = self.trainer.train_model(
                train_loader, val_loader, epochs, learning_rate
            )
            
            # ==============================================================================
            # æ¨¡å‹è¯„ä¼°é˜¶æ®µ
            # ==============================================================================
            print("\nğŸ“ˆ é˜¶æ®µ4: æ¨¡å‹è¯„ä¼°")
            self.evaluator = ModelEvaluator(self.model, self.data_processor.scaler, self.device)
            predictions, actuals, metrics = self.evaluator.evaluate_model(test_loader)
            
            # åæ ‡å‡†åŒ–é¢„æµ‹ç»“æœ
            predictions_inverse, actuals_inverse = self.evaluator.inverse_transform_predictions(
                predictions, actuals
            )
            
            # ==============================================================================
            # ç»“æœå¯è§†åŒ–é˜¶æ®µ
            # ==============================================================================
            print("\nğŸ¨ é˜¶æ®µ5: ç»“æœå¯è§†åŒ–")
            
            # è®­ç»ƒå†å²å¯è§†åŒ–
            self.visualizer.plot_training_history(
                train_losses, val_losses, self.trainer.learning_rates
            )
            
            # é¢„æµ‹ç»“æœå¯è§†åŒ–
            split_index = len(df) - len(predictions) - self.data_processor.sequence_length
            test_dates = df['æ—¥æœŸ'].iloc[split_index:split_index + len(predictions)].values
            
            self.visualizer.plot_predictions(
                predictions_inverse, actuals_inverse, test_dates, "è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç»“æœ"
            )
            
            # ==============================================================================
            # æœªæ¥é¢„æµ‹é˜¶æ®µ - ä¿®å¤ç‰ˆæœ¬
            # ==============================================================================
            print("\nğŸ”® é˜¶æ®µ6: æœªæ¥ä»·æ ¼é¢„æµ‹")
            
            # ä½¿ç”¨å¤„ç†åçš„æ•°æ®è€Œä¸æ˜¯åŸå§‹æ•°æ®
            processed_data = self.data_processor.get_processed_data()
            future_predictions = self.predict_future(processed_data, days=5)
            
            print("\næœªæ¥5å¤©ä»·æ ¼é¢„æµ‹:")
            print("å¤©æ•°\té¢„æµ‹ä»·æ ¼")
            print("-" * 20)
            for i, price in enumerate(future_predictions, 1):
                print(f"ç¬¬{i}å¤©\t{price:.2f}")
            
            return metrics
            
        except Exception as e:
            print(f"âŒ æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def predict_future(self, data, days=5):
        """é¢„æµ‹æœªæ¥ä»·æ ¼ - ä¿®å¤ç‰ˆæœ¬"""
        self.model.eval()
        
        # å‡†å¤‡æœ€åä¸€æ®µåºåˆ—æ•°æ®
        last_sequence = data[-self.data_processor.sequence_length:]
        last_sequence_scaled = self.data_processor.scaler.transform(last_sequence)
        
        predictions = []
        current_sequence = last_sequence_scaled.copy()
        
        with torch.no_grad():
            for i in range(days):
                # å‡†å¤‡è¾“å…¥æ•°æ®
                input_seq = torch.FloatTensor(current_sequence).unsqueeze(0).to(self.device)
                
                # é¢„æµ‹
                pred = self.model(input_seq)
                pred_value = pred.cpu().numpy()[0, 0]
                predictions.append(pred_value)
                
                # åˆ›å»ºæ–°çš„ä¸€è¡Œæ•°æ®ï¼ˆä½¿ç”¨é¢„æµ‹å€¼æ›´æ–°æ”¶ç›˜ä»·ï¼‰
                new_row = current_sequence[-1].copy()
                new_row[1] = pred_value  # å‡è®¾æ”¶ç›˜ä»·åœ¨ç´¢å¼•1
                
                # æ›´æ–°åºåˆ—
                current_sequence = np.vstack([current_sequence[1:], new_row])
        
        # åæ ‡å‡†åŒ–é¢„æµ‹ç»“æœ
        dummy = np.zeros((len(predictions), len(self.data_processor.scaler.scale_)))
        dummy[:, 1] = predictions
        predictions_inverse = self.data_processor.scaler.inverse_transform(dummy)[:, 1]
        
        return predictions_inverse

# ==============================================================================
# ä¸»å‡½æ•° - ä¿®å¤ç‰ˆæœ¬
# ==============================================================================
def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç³»ç»Ÿå¯åŠ¨")
    print("="*60)
    
    # æ•°æ®è·¯å¾„
    data_path = "data/stock_data/hist/600519/20240501_20250905_akshare.csv"
    
    # é¦–å…ˆå°è¯•ç®€åŒ–ç‰ˆæ¨¡å‹ï¼ˆæ›´ç¨³å®šï¼‰
    print("ğŸ”„ é¦–å…ˆå°è¯•ç®€åŒ–ç‰ˆæ¨¡å‹...")
    predictor = StockPricePredictor(
        sequence_length=10,      # æ—¶é—´åºåˆ—é•¿åº¦
        test_size=0.15,          # æµ‹è¯•é›†æ¯”ä¾‹
        validation_size=0.15,    # éªŒè¯é›†æ¯”ä¾‹
        use_simple_model=True    # ä½¿ç”¨ç®€åŒ–ç‰ˆæ¨¡å‹
    )
    
    try:
        # è¿è¡Œå®Œæ•´æµç¨‹
        metrics = predictor.run_pipeline(
            data_path=data_path,
            epochs=80,           # è®­ç»ƒè½®æ•°
            batch_size=16,       # æ‰¹å¤§å°
            learning_rate=0.001  # å­¦ä¹ ç‡
        )
        
        if metrics:
            print("\n" + "="*60)
            print("âœ… è‚¡ç¥¨ä»·æ ¼é¢„æµ‹æµç¨‹å®Œæˆ!")
            print("="*60)
            
            # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
            report = {
                'final_metrics': metrics,
                'model_info': {
                    'parameters': sum(p.numel() for p in predictor.model.parameters()),
                    'device': str(predictor.device),
                    'model_type': 'Simple'
                }
            }
            
            print(f"ğŸ“‹ æœ€ç»ˆæŠ¥å‘Š:")
            print(f"   æ¨¡å‹ç±»å‹: {report['model_info']['model_type']}")
            print(f"   æ¨¡å‹å‚æ•°é‡: {report['model_info']['parameters']:,}")
            print(f"   ä½¿ç”¨è®¾å¤‡: {report['model_info']['device']}")
            print(f"   æœ€ä½³RÂ²åˆ†æ•°: {metrics['R2']:.4f}")
            
            # å¦‚æœç®€åŒ–ç‰ˆæ¨¡å‹è¿è¡ŒæˆåŠŸï¼Œå¯ä»¥å°è¯•é«˜çº§æ¨¡å‹
            print("\n" + "="*60)
            print("ğŸ”„ ç°åœ¨å°è¯•é«˜çº§æ¨¡å‹...")
            print("="*60)
            
            advanced_predictor = StockPricePredictor(
                sequence_length=10,
                test_size=0.15,
                validation_size=0.15,
                use_simple_model=False  # ä½¿ç”¨é«˜çº§æ¨¡å‹
            )
            
            advanced_metrics = advanced_predictor.run_pipeline(
                data_path=data_path,
                epochs=100,
                batch_size=32,
                learning_rate=0.001
            )
            
            if advanced_metrics:
                print("\n" + "="*60)
                print("é«˜çº§æ¨¡å‹è¿è¡ŒæˆåŠŸ!")
                print("="*60)
                
    except Exception as e:
        print(f"âŒ æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
        print("ğŸ’¡ å»ºè®®: æ£€æŸ¥æ•°æ®æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼ï¼Œç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨")




# ==============================================================================
# ç¨‹åºå…¥å£
# ==============================================================================
if __name__ == "__main__":
    main()